import Foundation
import AVFoundation
import WhisperKit
import SharedModels

@MainActor
class StreamingTranscriptionTest {
    private var whisperKit: WhisperKit?
    private var audioStreamTranscriber: AudioStreamTranscriber?
    private var isStreaming = false
    
    // Track streaming results
    private var allConfirmedText: String = ""
    private var currentUnconfirmedText: String = ""
    private var lastProgressText: String = ""
    private var lastDisplayedLiveText: String = ""  // Track what we actually displayed
    private var isShowingProgress: Bool = false
    
    init() {
        print("ğŸ¯ Streaming Transcription Test")
        print("This test will continuously transcribe your speech in real-time chunks")
    }
    
    // MARK: - Terminal UI Helpers
    
    private func clearCurrentLine() {
        print("\r\u{001B}[K", terminator: "")
        fflush(stdout)
    }
    
    private func updateProgressLine(_ text: String) {
        // Only update if the text has actually changed
        if text != lastProgressText {
            clearCurrentLine()
            print("ğŸ”„ \(text)", terminator: "")
            fflush(stdout)
            isShowingProgress = true
            lastProgressText = text
        }
    }
    
    private func printConfirmed(_ text: String) {
        if isShowingProgress {
            clearCurrentLine()
            isShowingProgress = false
            lastProgressText = ""
        }
        print("âœ… \(text)")
        fflush(stdout)
    }
    
    private func printUnconfirmed(_ text: String) {
        if isShowingProgress {
            clearCurrentLine()
            isShowingProgress = false
            lastProgressText = ""
        }
        print("â³ \(text)")
        fflush(stdout)
    }
    
    private func printStatus(_ text: String) {
        if isShowingProgress {
            clearCurrentLine()
            isShowingProgress = false
            lastProgressText = ""
        }
        print("ğŸ”‡ \(text)")
        fflush(stdout)
    }
    
    func requestMicrophonePermission() async -> Bool {
        return await withCheckedContinuation { continuation in
            AVCaptureDevice.requestAccess(for: .audio) { granted in
                continuation.resume(returning: granted)
            }
        }
    }
    
    func loadWhisperModel() async throws {
        // Use a smaller, faster model for real-time streaming
        let modelName = "openai_whisper-tiny"
        let modelManager = WhisperModelManager.shared
        
        print("ğŸ“¦ Loading WhisperKit with model: \(modelName)")
        
        let modelPath = modelManager.getModelPath(for: modelName)
        if !modelManager.isModelDownloaded(modelName) {
            throw NSError(domain: "TestStreamingTranscription", code: 1, 
                         userInfo: [NSLocalizedDescriptionKey: "Model \(modelName) is not downloaded. Please run: swift run TestDownload"])
        }
        
        whisperKit = try await WhisperKit(
            modelFolder: modelPath.path,
            verbose: false,
            logLevel: .error
        )
        
        print("âœ… WhisperKit loaded successfully")
    }
    
    func setupStreamTranscriber() async throws {
        guard let whisperKit = whisperKit else {
            throw NSError(domain: "TestStreamingTranscription", code: 2, 
                         userInfo: [NSLocalizedDescriptionKey: "WhisperKit not initialized"])
        }
        
        // Create audio processor for streaming
        let audioProcessor = AudioProcessor()
        
        // Configure streaming options for real-time transcription
        let decodingOptions = DecodingOptions(
            verbose: false,
            task: .transcribe,
            language: "en",
            temperature: 0.0,
            temperatureFallbackCount: 2,
            sampleLength: 224,
            topK: 5,
            usePrefillPrompt: true,
            usePrefillCache: true,
            skipSpecialTokens: true,
            withoutTimestamps: false,
            clipTimestamps: [0],
            suppressBlank: true,
            supressTokens: nil
        )
        
        // Create the streaming transcriber with callback for real-time updates
        audioStreamTranscriber = AudioStreamTranscriber(
            audioEncoder: whisperKit.audioEncoder,
            featureExtractor: whisperKit.featureExtractor,
            segmentSeeker: whisperKit.segmentSeeker,
            textDecoder: whisperKit.textDecoder,
            tokenizer: whisperKit.tokenizer!,
            audioProcessor: audioProcessor,
            decodingOptions: decodingOptions,
            requiredSegmentsForConfirmation: 2,  // How many segments to keep unconfirmed
            silenceThreshold: 0.3,  // VAD threshold (0.0 = very sensitive, 1.0 = only loud speech)
            compressionCheckWindow: 60,
            useVAD: true,  // Enable voice activity detection
            stateChangeCallback: { [weak self] oldState, newState in
                Task { [weak self] in
                    self?.handleStateChange(oldState: oldState, newState: newState)
                }
            }
        )
        
        print("ğŸ”§ Audio stream transcriber configured")
        print("   - VAD enabled with silence threshold: 0.3")
        print("   - Requires 2 segments for confirmation")
        print("   - Using tiny model for low latency")
    }
    
    func startStreaming() async throws {
        guard let transcriber = audioStreamTranscriber else {
            throw NSError(domain: "TestStreamingTranscription", code: 3, 
                         userInfo: [NSLocalizedDescriptionKey: "Stream transcriber not initialized"])
        }
        
        guard !isStreaming else {
            print("âš ï¸ Already streaming")
            return
        }
        
        print("\nğŸ¤ Starting continuous streaming transcription...")
        print("ğŸ’¡ Real-time transcription with improved UI:")
        print("   ï¿½ LIVE: Updates in place as you speak")
        print("   â³ DRAFT: Unconfirmed segments (may change)")
        print("   âœ… Final confirmed segments")
        print("ğŸ›‘ Press Ctrl+C to stop\n")
        
        isStreaming = true
        
        try await transcriber.startStreamTranscription()
    }
    
    func stopStreaming() async {
        guard let transcriber = audioStreamTranscriber else { return }
        
        print("\nğŸ›‘ Stopping streaming transcription...")
        await transcriber.stopStreamTranscription()
        isStreaming = false
        
        // Print final summary
        print("\n" + String(repeating: "=", count: 50))
        print("ğŸ“‹ FINAL TRANSCRIPTION SUMMARY")
        print(String(repeating: "=", count: 50))
        if !allConfirmedText.isEmpty {
            print("âœ… Confirmed: \(allConfirmedText)")
        }
        if !currentUnconfirmedText.isEmpty {
            print("â³ Unconfirmed: \(currentUnconfirmedText)")
        }
        if allConfirmedText.isEmpty && currentUnconfirmedText.isEmpty {
            print("âŒ No transcription captured")
        }
        print(String(repeating: "=", count: 50))
    }
    
    private func handleStateChange(oldState: AudioStreamTranscriber.State, newState: AudioStreamTranscriber.State) {
        // Handle confirmed segments (these are final and won't change)
        if newState.confirmedSegments.count > oldState.confirmedSegments.count {
            let newSegments = Array(newState.confirmedSegments.suffix(newState.confirmedSegments.count - oldState.confirmedSegments.count))
            for segment in newSegments {
                let segmentText = segment.text.trimmingCharacters(in: .whitespacesAndNewlines)
                if !segmentText.isEmpty {
                    allConfirmedText += segmentText + " "
                    printConfirmed("\"\(segmentText)\"")
                }
            }
        }
        
        // Handle unconfirmed segments (these may change as more audio comes in)
        let newUnconfirmedText = newState.unconfirmedSegments.map { $0.text.trimmingCharacters(in: .whitespacesAndNewlines) }.joined(separator: " ")
        
        if newUnconfirmedText != currentUnconfirmedText && !newUnconfirmedText.isEmpty {
            currentUnconfirmedText = newUnconfirmedText
            printUnconfirmed("DRAFT: \"\(newUnconfirmedText)\"")
        }
        
        // Handle real-time progress text (immediate feedback) - update in place
        if newState.currentText != oldState.currentText {
            let progressText = newState.currentText.trimmingCharacters(in: .whitespacesAndNewlines)
            if progressText != "Waiting for speech..." && !progressText.isEmpty {
                updateProgressLine("LIVE: \"\(progressText)\"")
            } else if progressText == "Waiting for speech..." && lastProgressText != progressText {
                printStatus("Waiting for speech... (speak now)")
                lastProgressText = progressText
            }
        }
    }
}

@main
struct TestStreamingTranscription {
    static func main() async {
        print("ğŸ™ï¸  Real-Time Streaming Transcription Test")
        print("==========================================")
        print("This test demonstrates continuous, chunked transcription")
        print("similar to how modern voice assistants work.\n")
        
        let test = StreamingTranscriptionTest()
        
        // Simple approach - let the streaming run until user hits Ctrl+C
        // The operating system will handle the SIGINT signal
        
        do {
            // Check microphone permission
            print("ğŸ¤ Requesting microphone permission...")
            let hasPermission = await test.requestMicrophonePermission()
            
            guard hasPermission else {
                print("âŒ Microphone permission denied")
                print("Please grant microphone access in System Settings > Privacy & Security > Microphone")
                exit(1)
            }
            print("âœ… Microphone permission granted")
            
            // Load model
            print("\nğŸ“¦ Loading WhisperKit model...")
            try await test.loadWhisperModel()
            
            // Setup transcriber
            print("\nğŸ”§ Setting up streaming transcriber...")
            try await test.setupStreamTranscriber()
            
            // Start streaming
            try await test.startStreaming()
            
            // Keep running - user will press Ctrl+C to stop
            print("ğŸ”„ Streaming in progress... Press Ctrl+C to stop")
            while true {
                try await Task.sleep(nanoseconds: 1_000_000_000) // 1 second
            }
            
        } catch {
            print("âŒ Error: \(error)")
            await test.stopStreaming()
            exit(1)
        }
        
        print("\nğŸ‘‹ Test completed!")
    }
}
